{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f71a7e2029945daa6c3ea4b68ab6180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41361aa7c27841089a9169e56f4a85da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69faafca4bb34ea6b24e281845c924f2",
              "IPY_MODEL_3bfae5b8ae2347fc88c45a539bfa19e9"
            ]
          }
        },
        "41361aa7c27841089a9169e56f4a85da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69faafca4bb34ea6b24e281845c924f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c5775a8a0714c86bee83ffc1309de48",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87a3086fbbef4e43a491bbbcc5342701"
          }
        },
        "3bfae5b8ae2347fc88c45a539bfa19e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aee3c13b9721462a98ff75f9eb759070",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:31&lt;00:00, 32.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9042eeb8b4f46b7a8297e0a481e3a72"
          }
        },
        "2c5775a8a0714c86bee83ffc1309de48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87a3086fbbef4e43a491bbbcc5342701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aee3c13b9721462a98ff75f9eb759070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9042eeb8b4f46b7a8297e0a481e3a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75df0095acfc4e4489b4b16001fc4113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c8330974cbb4b06b979483dc8b1e346",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9265806a3c954c4e89e75de16f7fdce4",
              "IPY_MODEL_33a3271c03d0435abb294724e7599804"
            ]
          }
        },
        "6c8330974cbb4b06b979483dc8b1e346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9265806a3c954c4e89e75de16f7fdce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d57ae45c74394c2791cbff0153b7401b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24891b65998a4e9483155f4242b3ae6f"
          }
        },
        "33a3271c03d0435abb294724e7599804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a957199ceff0449e85a9b46855475875",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:28&lt;00:00, 16.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_027670759881431bb5f8257910d69b33"
          }
        },
        "d57ae45c74394c2791cbff0153b7401b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24891b65998a4e9483155f4242b3ae6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a957199ceff0449e85a9b46855475875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "027670759881431bb5f8257910d69b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "036cbe2d22b84b25b250042d2e9c4409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10f74669e1404994a3b7e13f04c2e5c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23c95d0ac2584ac08512f7fb9f6a3d95",
              "IPY_MODEL_73c7cb65f39a456e90e2cee47bccdbcc"
            ]
          }
        },
        "10f74669e1404994a3b7e13f04c2e5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23c95d0ac2584ac08512f7fb9f6a3d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dd2ddb8329d048078193a5e94daf4a83",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d20a6a73335142bc8fa0a9854d1384c1"
          }
        },
        "73c7cb65f39a456e90e2cee47bccdbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_715cdde3dadf4707b073605ad8606104",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:25&lt;00:00, 52.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ec4a8d6e3c644b1920b0b8412fc6d8a"
          }
        },
        "dd2ddb8329d048078193a5e94daf4a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d20a6a73335142bc8fa0a9854d1384c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "715cdde3dadf4707b073605ad8606104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ec4a8d6e3c644b1920b0b8412fc6d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ObrG6cYlMw"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bivKY5KZvAi",
        "outputId": "e15a66d2-9bb2-4120-f25b-6eb519107719"
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 10.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/31/4d4861a90d66c287a348fd17eaefefcdc2e859951cab9884b555923f046d/boto3-1.16.23-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.1MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/49/c8c99477416fdebb59078bda624acc5b3c7008f891c60d56d6ff1570d83e/botocore-1.19.23-py2.py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.23->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.23->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.19.23 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.16.23 botocore-1.19.23 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167,
          "referenced_widgets": [
            "0f71a7e2029945daa6c3ea4b68ab6180",
            "41361aa7c27841089a9169e56f4a85da",
            "69faafca4bb34ea6b24e281845c924f2",
            "3bfae5b8ae2347fc88c45a539bfa19e9",
            "2c5775a8a0714c86bee83ffc1309de48",
            "87a3086fbbef4e43a491bbbcc5342701",
            "aee3c13b9721462a98ff75f9eb759070",
            "d9042eeb8b4f46b7a8297e0a481e3a72",
            "75df0095acfc4e4489b4b16001fc4113",
            "6c8330974cbb4b06b979483dc8b1e346",
            "9265806a3c954c4e89e75de16f7fdce4",
            "33a3271c03d0435abb294724e7599804",
            "d57ae45c74394c2791cbff0153b7401b",
            "24891b65998a4e9483155f4242b3ae6f",
            "a957199ceff0449e85a9b46855475875",
            "027670759881431bb5f8257910d69b33",
            "036cbe2d22b84b25b250042d2e9c4409",
            "10f74669e1404994a3b7e13f04c2e5c6",
            "23c95d0ac2584ac08512f7fb9f6a3d95",
            "73c7cb65f39a456e90e2cee47bccdbcc",
            "dd2ddb8329d048078193a5e94daf4a83",
            "d20a6a73335142bc8fa0a9854d1384c1",
            "715cdde3dadf4707b073605ad8606104",
            "3ec4a8d6e3c644b1920b0b8412fc6d8a"
          ]
        },
        "id": "e10A_aLQYryl",
        "outputId": "b52a7cbb-8ef7-4d50-8115-65eed1abd026"
      },
      "source": [
        "from transformers import GPT2TokenizerFast\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f71a7e2029945daa6c3ea4b68ab6180",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75df0095acfc4e4489b4b16001fc4113",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "036cbe2d22b84b25b250042d2e9c4409",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRwZLn8FY1R6",
        "outputId": "e322aae6-119b-4796-d4d4-45866d5df00b"
      },
      "source": [
        "tokenizer(\"Hello I am 18\")['input_ids']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15496, 314, 716, 1248]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nazhGgSiZnSP"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import nltk\n",
        "\n",
        "from pytorch_pretrained_bert import (GPT2LMHeadModel, GPT2Tokenizer,\n",
        "                                     BertTokenizer, BertForMaskedLM)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class AbstractLanguageChecker():\n",
        "    \"\"\"\n",
        "    Abstract Class that defines the Backend API of GLTR.\n",
        "\n",
        "    To extend the GLTR interface, you need to inherit this and\n",
        "    fill in the defined functions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        In the subclass, you need to load all necessary components\n",
        "        for the other functions.\n",
        "        Typically, this will comprise a tokenizer and a model.\n",
        "        '''\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def check_probabilities(self, in_text, topk=40):\n",
        "        '''\n",
        "        Function that GLTR interacts with to check the probabilities of words\n",
        "\n",
        "        Params:\n",
        "        - in_text: str -- The text that you want to check\n",
        "        - topk: int -- Your desired truncation of the head of the distribution\n",
        "\n",
        "        Output:\n",
        "        - payload: dict -- The wrapper for results in this function, described below\n",
        "\n",
        "        Payload values\n",
        "        ==============\n",
        "        bpe_strings: list of str -- Each individual token in the text\n",
        "        real_topk: list of tuples -- (ranking, prob) of each token\n",
        "        pred_topk: list of list of tuple -- (word, prob) for all topk\n",
        "        '''\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def postprocess(self, token):\n",
        "        \"\"\"\n",
        "        clean up the tokens from any special chars and encode\n",
        "        leading space by UTF-8 code '\\u0120', linebreak with UTF-8 code 266 '\\u010A'\n",
        "        :param token:  str -- raw token text\n",
        "        :return: str -- cleaned and re-encoded token text\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "def top_k_logits(logits, k):\n",
        "    '''\n",
        "    Filters logits to only the top k choices\n",
        "    from https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py\n",
        "    '''\n",
        "    if k == 0:\n",
        "        return logits\n",
        "    values, _ = torch.topk(logits, k)\n",
        "    min_values = values[:, -1]\n",
        "    return torch.where(logits < min_values,\n",
        "                       torch.ones_like(logits, dtype=logits.dtype) * -1e10,\n",
        "                       logits)\n",
        "\n",
        "\n",
        "\n",
        "class LM(AbstractLanguageChecker):\n",
        "    def __init__(self, model_name_or_path=\"gpt2\"):\n",
        "        super(LM, self).__init__()\n",
        "        self.enc = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        self.start_token = '<|endoftext|>'\n",
        "        print(\"Loaded GPT-2 model!\")\n",
        "\n",
        "    def check_probabilities(self, in_text, topk=40):\n",
        "        # Process input\n",
        "        start_t = torch.full((1, 1),\n",
        "                             self.enc.encoder[self.start_token],\n",
        "                             device=self.device,\n",
        "                             dtype=torch.long)\n",
        "        context = self.enc.encode(in_text)\n",
        "        context = torch.tensor(context,\n",
        "                               device=self.device,\n",
        "                               dtype=torch.long).unsqueeze(0)\n",
        "        context = torch.cat([start_t, context], dim=1)\n",
        "        # Forward through the model\n",
        "        logits, _ = self.model(context)\n",
        "\n",
        "        # construct target and pred\n",
        "        yhat = torch.softmax(logits[0, :-1], dim=-1)\n",
        "        y = context[0, 1:]\n",
        "        # Sort the predictions for each timestep\n",
        "        sorted_preds = np.argsort(-yhat.data.cpu().numpy())\n",
        "        # [(pos, prob), ...]\n",
        "        real_topk_pos = list(\n",
        "            [int(np.where(sorted_preds[i] == y[i].item())[0][0])\n",
        "             for i in range(y.shape[0])])\n",
        "        real_topk_probs = yhat[np.arange(\n",
        "            0, y.shape[0], 1), y].data.cpu().numpy().tolist()\n",
        "        real_topk_probs = list(map(lambda x: round(x, 5), real_topk_probs))\n",
        "\n",
        "        real_topk = list(zip(real_topk_pos, real_topk_probs))\n",
        "        # [str, str, ...]\n",
        "        bpe_strings = [self.enc.decoder[s.item()] for s in context[0]]\n",
        "\n",
        "        bpe_strings = [self.postprocess(s) for s in bpe_strings]\n",
        "\n",
        "        # [[(pos, prob), ...], [(pos, prob), ..], ...]\n",
        "        pred_topk = [\n",
        "            list(zip([self.enc.decoder[p] for p in sorted_preds[i][:topk]],\n",
        "                     list(map(lambda x: round(x, 5),\n",
        "                              yhat[i][sorted_preds[i][\n",
        "                                      :topk]].data.cpu().numpy().tolist()))))\n",
        "            for i in range(y.shape[0])]\n",
        "\n",
        "        pred_topk = [[(self.postprocess(t[0]), t[1]) for t in pred] for pred in pred_topk]\n",
        "        payload = {'bpe_strings': bpe_strings,\n",
        "                   'real_topk': real_topk,\n",
        "                   'pred_topk': pred_topk}\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return payload\n",
        "\n",
        "    def sample_unconditional(self, length=100, topk=5, temperature=1.0):\n",
        "        '''\n",
        "        Sample `length` words from the model.\n",
        "        Code strongly inspired by\n",
        "        https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py\n",
        "\n",
        "        '''\n",
        "        context = torch.full((1, 1),\n",
        "                             self.enc.encoder[self.start_token],\n",
        "                             device=self.device,\n",
        "                             dtype=torch.long)\n",
        "        prev = context\n",
        "        output = context\n",
        "        past = None\n",
        "        # Forward through the model\n",
        "        with torch.no_grad():\n",
        "            for i in range(length):\n",
        "                logits, past = self.model(prev, past=past)\n",
        "                logits = logits[:, -1, :] / temperature\n",
        "                # Filter predictions to topk and softmax\n",
        "                probs = torch.softmax(top_k_logits(logits, k=topk),\n",
        "                                      dim=-1)\n",
        "                # Sample\n",
        "                prev = torch.multinomial(probs, num_samples=1)\n",
        "                # Construct output\n",
        "                output = torch.cat((output, prev), dim=1)\n",
        "\n",
        "        output_text = self.enc.decode(output[0].tolist())\n",
        "        return output_text\n",
        "\n",
        "    def postprocess(self, token):\n",
        "        with_space = False\n",
        "        with_break = False\n",
        "        if token.startswith('Ġ'):\n",
        "            with_space = True\n",
        "            token = token[1:]\n",
        "            # print(token)\n",
        "        elif token.startswith('â'):\n",
        "            token = ' '\n",
        "        elif token.startswith('Ċ'):\n",
        "            token = ' '\n",
        "            with_break = True\n",
        "\n",
        "        token = '-' if token.startswith('â') else token\n",
        "        token = '“' if token.startswith('ľ') else token\n",
        "        token = '”' if token.startswith('Ŀ') else token\n",
        "        token = \"'\" if token.startswith('Ļ') else token\n",
        "\n",
        "        if with_space:\n",
        "            token = '\\u0120' + token\n",
        "        if with_break:\n",
        "            token = '\\u010A' + token\n",
        "\n",
        "        return token\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDrEk1bOaEa3"
      },
      "source": [
        "raw_text = \"hello i am the student\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6sBPW8LZ4la",
        "outputId": "91b2b15d-afd0-481a-9e0d-7a1b0ebe35bd"
      },
      "source": [
        "lm = LM()\n",
        "payload = lm.check_probabilities(raw_text, topk=5)\n",
        "# print(payload[\"pred_topk\"])\n",
        "real_topK = payload[\"real_topk\"]\n",
        "ranks = [i[0] for i in real_topK]\n",
        "preds = [i[1] for i in real_topK]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded GPT-2 model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbi6O_S9aQ5S"
      },
      "source": [
        "def get_ranks(text, lm):\n",
        "  ranks_preds = lm.check_probabilities(raw_text)[\"real_topk\"]\n",
        "\n",
        "  return [i[0] for i in ranks_preds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtbol4TKixDG",
        "outputId": "4bf1ee75-4c33-47a8-8460-42138f7643c0"
      },
      "source": [
        "my_text = \"Hello my name is Mark\"\n",
        "\n",
        "get_ranks(my_text, lm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4481, 10, 1, 3, 182]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPA1Av9xjRfz"
      },
      "source": [
        "precond = \"Once upon a time\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Bp6FT1Jj36D",
        "outputId": "9cc4e14b-72df-4342-b46e-e7aeba8b2359"
      },
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "import torch\n",
        "\n",
        "model = GPT2Model.from_pretrained('gpt2', return_dict=True)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1Hr3xNknSlR"
      },
      "source": [
        "# Generating text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNhIcsVTmZPv"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "C4BGZ3-3kUqb",
        "outputId": "a840d426-a100-446b-f099-c2c17c3d54c3"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_ids = tokenizer.encode(precond, return_tensors='pt')\n",
        "\n",
        "# generate text until the output length (which includes the context length) reaches 50\n",
        "greedy_output = model.generate(\n",
        "    input_ids, \n",
        "    max_length=100, \n",
        "    num_beams=5, \n",
        "    no_repeat_ngram_size=2, \n",
        "    early_stopping=True\n",
        ")\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6f49a8e5096c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# encode context the generation is conditioned on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# generate text until the output length (which includes the context length) reaches 50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m greedy_output = model.generate(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    }
  ]
}